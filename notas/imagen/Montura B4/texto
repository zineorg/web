Ash Mills You are right. Here's a decent cut-paste from a Red forum that explains it - could be a sticky? - You need optical correction if you plan on delivering acceptable results - even at 2K.
" Sure, you can try to get away with less if your market or clients will only use Vimeo or small displays - or if they don't seem to care. But what happens someday when surprise - they project it on a large screen? That is your reputation that is at risk. Unfortunately, RED also suffers when someone watching remembers that is what it was shot with.
There is plenty of high quality 2/3" HD glass out there - primes, zooms - I own my own share. The form factor has advantages in some situations - I know exactly why you - and many others - pine for the same functionality in corporate, industrial and broadcast markets. We may yet see some manufacturers respond to this market need.
So why do adapters need optical correction?
The introduction of the B4 interface was a milestone - it was the first time in history that a common lens mount and specifications were adopted for all 2/3" HD cameras. (this was the Broadcast Technology Association global standard BTA S-1005-A adopted in 1994, followed by the EBU Tech Spec in 2002). Before this standard, every camera manufacturer had their own mounts and specifications. I could not use a Panasonic lens on a Sony, or an Ikegami. Sometimes you ordered a new camera based not on its features, but on the glass you owned.
In establishing the B4 standard, a specific 48mm flange back dimension was dictated - this is where the green image "in air" plane is that you see reference marked on the side of the camera - and what you "back focused" to.
If you are only looking at one part of the light spectrum, that would be easy - and the end of the story. Chances are that you are not shooting black & white - where the green channel would be enough for luminance. Color adds a degree of complexity.
There is a brilliant engineer I know from Sennheiser who likes to say that "Everything in life is a wave" (Thank you Volker!!!).
He is right - when you are talking about capturing images, those beams of light travel through the lens at different wavelengths - therefore they focus at different planes. This is what is called "longitudinal chromatic aberration". There is a secondary issue - when they focus at different distances, their size (magnification) is different - this is referred to as lateral chromatic aberration.
In the case of 2/3" HD cameras, the light is split by a prism to land on 3 sensors. The prism assemblies are designed to mitigate both types of aberrations by offsetting the sensors - Red is offset by 10 micrometers and Blue is offset by 4 micrometers from the Green image plane. This is a compromise - but take away those modifications and you end up with real problems ( aka inferior results).
The B4 lenses are designed - as a worldwide standard - to pass the light waves into a camera with the above factored in.
That means that without optical correction, any B4 adapter would pass a flawed image onto a single sensor.
There is no work around once you capture it wrong."

Lee Mullen
As I said, I dont see much of a difference whether the tradition prism or 3CCD sensor is used vs 1 chip CMOS sensor. I've done extensive tests over there years and the fact is that the bloom/low contrast/haze/CA is down the lens and the overall design. Gee even 4K B4 lenses still exhibit the same issue!
